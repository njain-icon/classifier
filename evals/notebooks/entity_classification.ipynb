{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e0f5ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/nishanjain/Desktop/oran/classifier/myenv/lib/python3.13/site-packages (2.3.3)\n",
      "Requirement already satisfied: requests in /Users/nishanjain/Desktop/oran/classifier/myenv/lib/python3.13/site-packages (2.32.5)\n",
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/nishanjain/Desktop/oran/classifier/myenv/lib/python3.13/site-packages (from pandas) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/nishanjain/Desktop/oran/classifier/myenv/lib/python3.13/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/nishanjain/Desktop/oran/classifier/myenv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/nishanjain/Desktop/oran/classifier/myenv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/nishanjain/Desktop/oran/classifier/myenv/lib/python3.13/site-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nishanjain/Desktop/oran/classifier/myenv/lib/python3.13/site-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/nishanjain/Desktop/oran/classifier/myenv/lib/python3.13/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nishanjain/Desktop/oran/classifier/myenv/lib/python3.13/site-packages (from requests) (2025.10.5)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/nishanjain/Desktop/oran/classifier/myenv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas requests openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "23b61c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Entity classification mapping dictionary.\n",
    "\n",
    "This dictionary maps entity types to their corresponding identifiers\n",
    "used in the entity classification system.\n",
    "\"\"\"\n",
    "\n",
    "mapping_dict = {\n",
    "#\"LLM_PERSON\": \"person-name\",\n",
    "#\"STREET_ADDRESS\": \"street-address\",\n",
    "\"DATE_OF_BIRTH\": \"date-of-birth\",\n",
    "\"US_SSN\": \"us-ssn\",\n",
    "\"US_DRIVER_LICENSE\": \"us-drivers-license\",\n",
    "\"PHONE_NUMBER\": \"phone-number\",\n",
    "\"EMAIL_ADDRESS\": \"email-address\",\n",
    "\"US_BANK_NUMBER\": \"us-bank-account-number\",\n",
    "\"ROUTING_NUMBER\": \"bank-routing-number\",\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e697a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from typing import Tuple, List, Dict, Any, Set\n",
    "from typing import Dict\n",
    "from collections import defaultdict\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0ddd6ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_classification_api(text, mode=\"all\", anonymize=False):\n",
    "    \"\"\"\n",
    "    Call the Pebblo classification API\n",
    "    \n",
    "    Args:\n",
    "        text (str): The text to classify\n",
    "        mode (str): Classification mode - \"all\", \"entity\", or \"topic\"\n",
    "        anonymize (bool): Whether to anonymize the results\n",
    "    \n",
    "    Returns:\n",
    "        dict: The classification response\n",
    "    \"\"\"\n",
    "    url = \"http://localhost:8000/api/v1/classify\"\n",
    "    \n",
    "    # Prepare the request payload without llm_config\n",
    "    payload = {\n",
    "        \"text\": text,\n",
    "        \"anonymize\": anonymize,\n",
    "        \"country_list\": [\"US\"]\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        #print(\"payload\", payload)\n",
    "        response = requests.post(url, json=payload)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error making API request: {e}\")\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "64ee3b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_entity_test_data(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads the entity test data from an Excel file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the Excel file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the test data.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the file does not exist.\n",
    "        ValueError: If the file cannot be read as an Excel file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_excel(file_path)\n",
    "        return df\n",
    "    except FileNotFoundError as fnf_err:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        raise fnf_err\n",
    "    except Exception as exc:\n",
    "        print(f\"Error reading Excel file: {exc}\")\n",
    "        raise ValueError(f\"Could not read Excel file: {file_path}\") from exc\n",
    "\n",
    "# Example usage:\n",
    "# test_data_df = read_entity_test_data(\"entity_test_data.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2ce54264",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_excel=\"../test_data/final_entity_dataset.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cce3ba17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_excel=\"../test_data/final_entity_dataset_v7.xlsx\"\n",
    "test_data_df = read_entity_test_data(input_excel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "874221bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"Experiment_13\"\n",
    "description = \"\"\n",
    "tags = []\n",
    "test_column = \"mapped_output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "92f840a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_api_response_to_entity_list(api_response: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Converts an API response with 'entityDetails' and 'data' fields into a list of entity dicts\n",
    "    in the format: {'start': int, 'end': int, 'label': str, 'extracted_text': str}.\n",
    "\n",
    "    Args:\n",
    "        api_response (Dict[str, Any]): The API response containing 'entityDetails' and 'data'.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict[str, Any]]: List of entities in the required format.\n",
    "\n",
    "    Raises:\n",
    "        KeyError: If required keys are missing in the API response.\n",
    "        ValueError: If location format is invalid.\n",
    "    \"\"\"\n",
    "    entities: List[Dict[str, Any]] = []\n",
    "    entity_details = api_response.get(\"entityDetails\", {})\n",
    "    text_data = api_response.get(\"data\", \"\")\n",
    "\n",
    "    if not entity_details or not isinstance(entity_details, dict):\n",
    "        return entities\n",
    "\n",
    "    for label, entity_list in entity_details.items():\n",
    "        for entity in entity_list:\n",
    "            location = entity.get(\"location\")\n",
    "            if not location or \"_\" not in location:\n",
    "                continue\n",
    "            try:\n",
    "                start_str, end_str = location.split(\"_\")\n",
    "                start = int(start_str)\n",
    "                end = int(end_str)\n",
    "                extracted_text = text_data[start:end]\n",
    "                entities.append({\n",
    "                    \"start\": start,\n",
    "                    \"end\": end,\n",
    "                    \"label\": label,\n",
    "                    \"extracted_text\": extracted_text\n",
    "                })\n",
    "            except (ValueError, TypeError) as exc:\n",
    "                print(f\"Skipping entity with invalid location '{location}': {exc}\")\n",
    "                continue\n",
    "    return entities\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0975e716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0 of 1632\n",
      "Processing row 100 of 1632\n",
      "Processing row 200 of 1632\n",
      "Processing row 300 of 1632\n",
      "Processing row 400 of 1632\n",
      "Processing row 500 of 1632\n",
      "Processing row 600 of 1632\n",
      "Processing row 700 of 1632\n",
      "Processing row 800 of 1632\n",
      "Processing row 900 of 1632\n",
      "Processing row 1000 of 1632\n",
      "Processing row 1100 of 1632\n",
      "Processing row 1200 of 1632\n",
      "Processing row 1300 of 1632\n",
      "Processing row 1400 of 1632\n",
      "Processing row 1500 of 1632\n",
      "Processing row 1600 of 1632\n"
     ]
    }
   ],
   "source": [
    "def aggregate_classification_results(\n",
    "    df: pd.DataFrame, text_column: str = \"text\", max_workers: int = 6\n",
    ") -> (List[Dict[str, Any]], List[float]):\n",
    "    \"\"\"\n",
    "    Iterates over each row in the DataFrame, sends the specified text column to the classification API in parallel,\n",
    "    and aggregates the results in a list.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing the test data.\n",
    "        text_column (str): Name of the column containing the text to classify.\n",
    "        max_workers (int): Maximum number of threads to use for parallel processing.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[Dict[str, Any]], List[float]]: List of classification results and response times for each row.\n",
    "\n",
    "    Raises:\n",
    "        KeyError: If the specified text_column does not exist in the DataFrame.\n",
    "    \"\"\"\n",
    "    if text_column not in df.columns:\n",
    "        raise KeyError(f\"Column '{text_column}' not found in DataFrame.\")\n",
    "\n",
    "    results: List[Any] = [None] * len(df)\n",
    "    response_time: List[float] = [0.0] * len(df)\n",
    "\n",
    "    def process_row(idx: int, text: str):\n",
    "        if idx % 100 == 0:\n",
    "            print(f\"Processing row {idx} of {len(df)}\")\n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            result = call_classification_api(text, mode=\"entity\")\n",
    "            converted = convert_api_response_to_entity_list(result)\n",
    "        except Exception as exc:\n",
    "            print(f\"Error processing row {idx}: {exc}\")\n",
    "            converted = {\"row_index\": idx, \"error\": str(exc)}\n",
    "        end_time = time.time()\n",
    "        return idx, converted, end_time - start_time\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_idx = {\n",
    "            executor.submit(process_row, idx, row.get(text_column, \"\")): idx\n",
    "            for idx, row in df.iterrows()\n",
    "        }\n",
    "        for future in as_completed(future_to_idx):\n",
    "            idx, converted, elapsed = future.result()\n",
    "            results[idx] = converted\n",
    "            response_time[idx] = elapsed\n",
    "\n",
    "    return results, response_time\n",
    "\n",
    "\n",
    "# Aggregate results for the first 10 rows\n",
    "start_time = time.time()\n",
    "classification_results, response_time = aggregate_classification_results(\n",
    "    test_data_df, text_column=\"text\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e4dba870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "test_data_df[f\"response_time_{experiment_name}\"] = response_time\n",
    "test_data_df[f\"classification_results_{experiment_name}\"] = classification_results\n",
    "test_data_df.to_excel(input_excel, index=False)\n",
    "experiment_time = time.time() - start_time\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "42c044bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entity_pairs_from_list(entity_list: List[dict]) -> Set[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Extracts (entity_type, value) pairs from a list of entity dicts.\n",
    "\n",
    "    Args:\n",
    "        entity_list (List[dict]): List of entity dicts, each with at least 'label' and 'extracted_text' keys.\n",
    "\n",
    "    Returns:\n",
    "        Set[Tuple[str, str]]: Set of (entity_type, value) pairs.\n",
    "    \"\"\"\n",
    "    entity_pairs = set()\n",
    "    if not isinstance(entity_list, list):\n",
    "        return entity_pairs\n",
    "    for ent in entity_list:\n",
    "        ent_type = ent.get(\"label\")\n",
    "        value = ent.get(\"extracted_text\").strip()\n",
    "        if ent_type is not None and value is not None:\n",
    "            entity_pairs.add((ent_type, str(value)))\n",
    "    return entity_pairs\n",
    "\n",
    "def compute_entity_metrics_for_lists(\n",
    "    df: pd.DataFrame,\n",
    "    actual_col: str = \"mapped_output\",\n",
    "    pred_col: str = None,\n",
    ") -> Tuple[pd.DataFrame, Dict[str, float]]:\n",
    "    \"\"\"\n",
    "    Computes per-entity and overall metrics (accuracy, precision, recall, F1) for entity classification,\n",
    "    assuming both actual and predicted entities are lists of dicts.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with ground truth in `actual_col`.\n",
    "        classification_results (List[List[dict]]): List of predicted entity lists (one per row).\n",
    "        actual_col (str): Name of the column with actual entity lists.\n",
    "        pred_col (str, optional): If not None, use this column in df for predicted entity lists.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame, Dict[str, float]]: (Per-entity metrics DataFrame, overall metrics dict)\n",
    "    \"\"\"\n",
    "    entity_stats = defaultdict(lambda: {\n",
    "        \"support\": 0,\n",
    "        \"actual_count\": 0,\n",
    "        \"correct\": 0,\n",
    "        \"extra\": 0,\n",
    "        \"missed\": 0,\n",
    "        \"wrong\": 0,\n",
    "        \"tp\": 0,\n",
    "        \"fp\": 0,\n",
    "        \"fn\": 0,\n",
    "    })\n",
    "\n",
    "    all_entity_types = set()\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        # Get actual entities as list of dicts\n",
    "        actual_entities = row[actual_col]\n",
    "        # INSERT_YOUR_CODE\n",
    "        # Replace any curly single quotes (‘ or ’) with straight single quotes (')\n",
    "        if isinstance(actual_entities, str):\n",
    "            actual_entities = actual_entities.replace('‘', \"'\").replace('’', \"'\")\n",
    "            #actual_entities = actual_entities.replace('’', \"'\")\n",
    "            actual_entities = actual_entities.replace('‘', '\"')\n",
    "        pred_entities = row[pred_col]\n",
    "\n",
    "        if isinstance(actual_entities, str):\n",
    "            try:\n",
    "                actual_entities = eval(actual_entities)\n",
    "            except Exception as e:\n",
    "                print(\"Exception in actual_entities\", e)\n",
    "                actual_entities = []\n",
    "        if not isinstance(actual_entities, list):\n",
    "            actual_entities = []\n",
    "        if isinstance(pred_entities, str):\n",
    "            try:\n",
    "                pred_entities = eval(pred_entities)\n",
    "            except Exception as e:\n",
    "                print(\"Exception in pred_entities\", e)\n",
    "                pred_entities = []\n",
    "        if not isinstance(pred_entities, list):\n",
    "            pred_entities = []\n",
    "        # Build sets of (entity_type, value) for actual and predicted\n",
    "\n",
    "        actual_set = extract_entity_pairs_from_list(actual_entities)\n",
    "        pred_set = extract_entity_pairs_from_list(pred_entities)\n",
    "\n",
    "\n",
    "        actual_types = set([et for et, _ in actual_set])\n",
    "        pred_types = set([et for et, _ in pred_set])\n",
    "        all_types = actual_types | pred_types\n",
    "        all_entity_types.update(all_types)\n",
    "\n",
    "        # Update support and actual_count\n",
    "        for ent_type in actual_types:\n",
    "            entity_stats[ent_type][\"support\"] += 1\n",
    "            entity_stats[ent_type][\"actual_count\"] += sum(1 for t, _ in actual_set if t == ent_type)\n",
    "\n",
    "        # For each entity type, update stats\n",
    "        for ent_type in all_types:\n",
    "            actual_vals = set([v for t, v in actual_set if t == ent_type])\n",
    "            pred_vals = set([v for t, v in pred_set if t == ent_type])\n",
    "            correct = actual_vals & pred_vals\n",
    "            extra = pred_vals - actual_vals\n",
    "            missed = actual_vals - pred_vals\n",
    "            # \"wrong\" is not well-defined for this case, but we keep it for compatibility\n",
    "            wrong = set()\n",
    "\n",
    "            entity_stats[ent_type][\"correct\"] += len(correct)\n",
    "            entity_stats[ent_type][\"extra\"] += len(extra)\n",
    "            entity_stats[ent_type][\"missed\"] += len(missed)\n",
    "            entity_stats[ent_type][\"wrong\"] += len(wrong)\n",
    "            entity_stats[ent_type][\"tp\"] += len(correct)\n",
    "            entity_stats[ent_type][\"fp\"] += len(extra)\n",
    "            entity_stats[ent_type][\"fn\"] += len(missed)\n",
    "\n",
    "    # Compute metrics per entity\n",
    "    metrics = []\n",
    "    for ent_type in sorted(all_entity_types):\n",
    "        stats = entity_stats[ent_type]\n",
    "        tp = stats[\"tp\"]\n",
    "        fp = stats[\"fp\"]\n",
    "        fn = stats[\"fn\"]\n",
    "        support = stats[\"support\"]\n",
    "        actual_count = stats[\"actual_count\"]\n",
    "        denom = tp + fp + fn\n",
    "        accuracy = tp / denom if denom > 0 else 0.0\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "        metrics.append({\n",
    "            \"entity_type\": ent_type,\n",
    "            \"actual_count\": actual_count,\n",
    "            \"support\": support,\n",
    "            \"correct\": stats[\"correct\"],\n",
    "            \"extra\": stats[\"extra\"],\n",
    "            \"missed\": stats[\"missed\"],\n",
    "            \"wrong\": stats[\"wrong\"],\n",
    "            \"accuracy\": accuracy,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1\": f1\n",
    "        })\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "    # Compute macro averages (across all entities)\n",
    "    macro = {}\n",
    "    for metric in [\"accuracy\", \"precision\", \"recall\", \"f1\"]:\n",
    "        macro[f\"macro_{metric}\"] = metrics_df[metric].mean() if not metrics_df.empty else 0.0\n",
    "\n",
    "    return metrics_df, macro\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3c540a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_type</th>\n",
       "      <th>actual_count</th>\n",
       "      <th>correct</th>\n",
       "      <th>extra</th>\n",
       "      <th>missed</th>\n",
       "      <th>wrong</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>email-address</td>\n",
       "      <td>290</td>\n",
       "      <td>281</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.959044</td>\n",
       "      <td>0.989437</td>\n",
       "      <td>0.968966</td>\n",
       "      <td>0.979094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>us-ssn</td>\n",
       "      <td>129</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.689922</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.689922</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phone-number</td>\n",
       "      <td>275</td>\n",
       "      <td>153</td>\n",
       "      <td>95</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>0.413514</td>\n",
       "      <td>0.616935</td>\n",
       "      <td>0.556364</td>\n",
       "      <td>0.585086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     entity_type  actual_count  correct  extra  missed  wrong  accuracy  \\\n",
       "0  email-address           290      281      3       9      0  0.959044   \n",
       "1         us-ssn           129       89      0      40      0  0.689922   \n",
       "2   phone-number           275      153     95     122      0  0.413514   \n",
       "\n",
       "   precision    recall        f1  \n",
       "0   0.989437  0.968966  0.979094  \n",
       "1   1.000000  0.689922  0.816514  \n",
       "2   0.616935  0.556364  0.585086  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro-averaged metrics across all entities:\n",
      "macro_accuracy: 0.071\n",
      "macro_precision: 0.090\n",
      "macro_recall: 0.076\n",
      "macro_f1: 0.082\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "# Assume test_data_df[\"mapped_output\"] and classification_results are both lists of dicts per row\n",
    "entity_metrics_df, macro_metrics = compute_entity_metrics_for_lists(\n",
    "    test_data_df, actual_col=test_column, pred_col=f\"classification_results_{experiment_name}\"\n",
    ")\n",
    "# Sort the entity_metrics_df by f1 score in descending order for better interpretability\n",
    "entity_metrics_df = entity_metrics_df.sort_values(by=\"f1\", ascending=False).reset_index(drop=True)\n",
    "entity_metrics_df = entity_metrics_df[entity_metrics_df[\"f1\"] > 0].reset_index(drop=True)\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "display(entity_metrics_df[[\"entity_type\", \"actual_count\", \"correct\", \"extra\", \"missed\", \"wrong\", \"accuracy\", \"precision\", \"recall\", \"f1\"]])\n",
    "print(\"Macro-averaged metrics across all entities:\")\n",
    "for k, v in macro_metrics.items():\n",
    "    print(f\"{k}: {v:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73212756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Experiment_11'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f288795e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of NaN values in test_data_df: 294\n",
      "Number of NaN values in 'classification_results': 147\n"
     ]
    }
   ],
   "source": [
    "# Count the number of NaN values in the test_data_df DataFrame\n",
    "nan_count = test_data_df.isna().sum().sum()\n",
    "print(f\"Total number of NaN values in test_data_df: {nan_count}\")\n",
    "# Identify columns in test_data_df that contain NaN values and print them\n",
    "\n",
    "def print_columns_with_nan(df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Prints the names of columns in the DataFrame that contain NaN values.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to check for NaN values.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    nan_columns = df.columns[df.isna().any()].tolist()\n",
    "    if nan_columns:\n",
    "        print(f\"Columns with NaN values: {nan_columns}\")\n",
    "    else:\n",
    "        print(\"No columns contain NaN values.\")\n",
    "\n",
    "num_nan_classification_results = test_data_df[\"classification_results\"].isna().sum()\n",
    "print(f\"Number of NaN values in 'classification_results': {num_nan_classification_results}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "75184544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text                                        We'll also be discussing the significance of AB+ in medical emergencies and how MRN123456789 can help streamline healthcare services. Don't miss our conversation with John from General Hospital.\n",
       "mapped_output                          [{'extracted_text': 'MRN123456789', 'label': 'medical-record-number', 'start': 80, 'end': 92}, {'extracted_text': 'John', 'label': 'person-name', 'start': 167, 'end': 171}, {'extracted_text': 'Gen...\n",
       "response_time                                                                                                                                                                                                                              NaN\n",
       "classification_results                                                                                                                                                                                                                     NaN\n",
       "response_time_Experiment_3                                                                                                                                                                                                             2.98595\n",
       "classification_results_Experiment_3                                                                                                             [{'start': 80, 'end': 92, 'label': 'medical-record-number', 'extracted_text': 'MRN123456789'}]\n",
       "response_time_Experiment_4                                                                                                                                                                                                            3.488992\n",
       "classification_results_Experiment_4                                                                                                             [{'start': 80, 'end': 92, 'label': 'medical-record-number', 'extracted_text': 'MRN123456789'}]\n",
       "response_time_Experiment_2                                                                                                                                                                                                            2.492888\n",
       "classification_results_Experiment_2                                                                                                                                                                                                         []\n",
       "Name: 1395, dtype: object"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_df.iloc[1395]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f7df1653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def get_rows_with_extra_entity(\n",
    "    test_data_df: pd.DataFrame,\n",
    "    entity_label: str,\n",
    "    actual_col: str = \"mapped_output\",\n",
    "    pred_col: str = \"classification_results\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns rows from test_data_df where the specified entity_label was detected as extra\n",
    "    in classification_results (i.e., present in prediction but not in mapped_output).\n",
    "\n",
    "    Only the specified entity_label is checked. The entity_label should match the label\n",
    "    used in the entity extraction output (e.g., 'bank-account-number', 'ssn', etc.).\n",
    "\n",
    "    Args:\n",
    "        test_data_df (pd.DataFrame): The original test data DataFrame.\n",
    "        classification_results (list[dict]): List of dicts with extracted entities per row.\n",
    "        entity_label (str): The entity type to check for extra detections.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Subset of test_data_df where entity_label was extra.\n",
    "    \"\"\"\n",
    "    extra_indices = []\n",
    "    for idx, (actual, predicted) in enumerate(\n",
    "        zip(test_data_df[actual_col], test_data_df[pred_col])\n",
    "    ):\n",
    "        # Ensure 'actual' is a list of dicts, not a string\n",
    "        if isinstance(actual, str):\n",
    "            try:\n",
    "                import ast\n",
    "                actual = actual.replace('‘', \"'\").replace('’', \"'\")\n",
    "            #actual_entities = actual_entities.replace('’', \"'\")\n",
    "                actual = actual.replace('‘', '\"')\n",
    "                actual = ast.literal_eval(actual)\n",
    "            except (ValueError, SyntaxError):\n",
    "                actual = []\n",
    "        # Only consider entities of the specified label\n",
    "        actual_entities = [\n",
    "            ent for ent in actual if ent.get(\"label\") == entity_label\n",
    "        ]\n",
    "        if isinstance(predicted, str):\n",
    "            try:\n",
    "                import ast\n",
    "                predicted = ast.literal_eval(predicted)\n",
    "                print(\"predicted\",predicted)\n",
    "            except (ValueError, SyntaxError):\n",
    "                predicted_entities = []\n",
    "\n",
    "        try:    \n",
    "            predicted_entities = [\n",
    "                ent for ent in predicted if ent.get(\"label\") == entity_label\n",
    "            ]  \n",
    "        except:\n",
    "            print(\"predicted - idx\",idx, predicted)\n",
    "            predicted_entities = []\n",
    "\n",
    "        # If there are predicted entities but none actual, mark as extra\n",
    "        if predicted_entities and not actual_entities:\n",
    "            extra_indices.append(idx)\n",
    "        else:\n",
    "            # Check if any predicted entity is not matched by actual (by extracted_text or span)\n",
    "            for pred_ent in predicted_entities:\n",
    "                match_found = any(\n",
    "                    (pred_ent.get(\"extracted_text\") == act_ent.get(\"extracted_text\"))\n",
    "                    or (\n",
    "                        pred_ent.get(\"start\") == act_ent.get(\"start\")\n",
    "                        and pred_ent.get(\"end\") == act_ent.get(\"end\")\n",
    "                    )\n",
    "                    for act_ent in actual_entities\n",
    "                )\n",
    "                if not match_found:\n",
    "                    extra_indices.append(idx)\n",
    "                    break  # Only need to add the row once\n",
    "\n",
    "    return test_data_df.iloc[extra_indices]\n",
    "\n",
    "# Example usage:\n",
    "# To get rows with extra detections for a specific entity type, e.g., \"bank-account-number\" or \"ssn\":\n",
    "# extra_bank_account_rows = get_rows_with_extra_entity(test_data_df, classification_results, \"bank-account-number\")\n",
    "extra_entity = get_rows_with_extra_entity(test_data_df, \"uk-sort-code\", \"mapped_output\", f\"classification_results_{experiment_name}\")\n",
    "len(extra_entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "4c9b3af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'classification_results_Experiment_10'"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"classification_results_{experiment_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "fa89c072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted phone numbers: ['020 1234 5678', '020 7890 1234', '020 1234 5678', '020 9876 5432', '0161 1234 567', '(800) 123-4567', '(123) 456-7890', '020 1234 5678', '02-566307-10', '123-456-7890', '555-555-5555', '555-555-5556', ' +44 20 1234 5678', '+44 20 1234 5678', '555-555-5555', '0333 200 101', '555-555-5555', ' +44-20-1234-5678', '1-800-123-4567', '020 1234 5678', '074427644', '1-800-123-4567', '[+1-540-555-1212', '+1-540-555-1212', '+1-540-555-1212', '+44 712345678', '(123) 456-7890', '(123) 456-1234', '(123) 456-7890', '(123) 456-7890', '[555-123-4567', '555-123-4567', '555-123-4567', '[555-987-6543', '555-987-6543', '555-987-6543', '1-800-123-4567', '1-800-987-6543', '1-800-111-2222', '(800) 123-4567', '+44 712345678', '1-800-123-4567', '555-555-5555', '+44 712345678', '+1-123-456-7890', '(026981968', '020 1234 5678', '020 9876 5432', '020 1234 5678', '020 7890 1234', '+44 712345678', '7237351878', '(7237351878', '+44 7891234567', '+44 7123456789', '0987-6543-2101', '(123) 456-7890', ' +44 20 1234 5678', '+44 7981 123 456', '+44 7123 456 789', '(123) 456-7890', '(123) 456-7890', '(123) 456-7890', '532-77-5372', '020 1234 5678', '740-33-5800', '972-77-4533', '099045584', '# 094114261', '284-38-7491', '933-87-4300', '180092680820429', '170-65-3779', '248-13-8141', '0299116078', '510-80-5258', '020205364', '0299116078', '956-64-3775', '170-25-0000', '275-40-0000', '924-21-3254', '214-80-0000', '900-70-0000', '782-44-0000', '653-90-0000', '1234-567-890', '077-32-0000', '900-75-5566', '900-70-0000', '494-00-1296', '9999-8888-7777', '9999888877776666', '080960416', '072225567', '213193066206554', '(212) 555-0198', '+39 06 12345678', '+39 06 87654321', '+39 345 9876543', '(+1-206-555-0198)', '+1-425-555-3478', '(954) 555-0198', '954-1023-786']\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict, Any\n",
    "import ast\n",
    "\n",
    "def extract_entities_from_results(\n",
    "    rows_df,\n",
    "    classification_results: List[List[Dict[str, Any]]],\n",
    "    entity_label: str\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    \n",
    "    Extracts the specified entity from classification_results for the given rows.\n",
    "\n",
    "    Args:\n",
    "        rows_df (pd.DataFrame): DataFrame containing the rows of interest (e.g., extra_entity).\n",
    "        classification_results (List[List[Dict[str, Any]]]): List of entity dicts per row.\n",
    "        entity_label (str): The entity type to extract.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: List of extracted entity texts for the specified entity_label.\n",
    "    \"\"\"\n",
    "    extracted_entities = []\n",
    "    for idx in rows_df.index:\n",
    "        # Defensive: classification_results may be a list of dicts or a string\n",
    "        row_results = classification_results[idx]\n",
    "        if isinstance(row_results, str):\n",
    "            try:\n",
    "                row_results = ast.literal_eval(row_results)\n",
    "            except (ValueError, SyntaxError):\n",
    "                row_results = []\n",
    "        for ent in row_results:\n",
    "            if ent.get(\"label\") == entity_label and \"extracted_text\" in ent:\n",
    "                extracted_entities.append(ent[\"extracted_text\"])\n",
    "    return extracted_entities\n",
    "\n",
    "# Example usage:\n",
    "# Extract all phone numbers from extra_entity rows\n",
    "phone_numbers = extract_entities_from_results(extra_entity, classification_results, \"phone-number\")\n",
    "print(\"Extracted phone numbers:\", phone_numbers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "43a7e214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phone_numbers.index('284-38-7491')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "872ddc65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all rows where 'bank-routing-number' was missed\n",
    "def get_rows_with_missed_entity(\n",
    "    test_data_df: pd.DataFrame,\n",
    "    classification_results: list[dict],\n",
    "    entity_label: str\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns rows from test_data_df where the specified entity_label was missed in classification_results.\n",
    "\n",
    "    Args:\n",
    "        test_data_df (pd.DataFrame): The original test data DataFrame.\n",
    "        classification_results (list[dict]): List of dicts with extracted entities per row.\n",
    "        entity_label (str): The entity type to check for missed detections.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Subset of test_data_df where entity_label was missed.\n",
    "    \"\"\"\n",
    "    missed_indices = []\n",
    "    for idx, (actual, predicted) in enumerate(\n",
    "        zip(test_data_df[\"mapped_output\"], classification_results)\n",
    "    ):\n",
    "        # Ensure 'actual' is a list of dicts, not a string\n",
    "        if isinstance(actual, str):\n",
    "            try:\n",
    "                import ast\n",
    "                actual = ast.literal_eval(actual)\n",
    "            except (ValueError, SyntaxError):\n",
    "                actual = []\n",
    "        # Get all actual entities of the target type\n",
    "        actual_entities = [\n",
    "            ent for ent in actual if ent.get(\"label\") == entity_label\n",
    "        ]\n",
    "        # Get all predicted entities of the target type\n",
    "        predicted_entities = [\n",
    "            ent for ent in predicted if ent.get(\"label\") == entity_label\n",
    "        ]\n",
    "        # If there are actual entities but none predicted, mark as missed\n",
    "        if actual_entities and not predicted_entities:\n",
    "            missed_indices.append(idx)\n",
    "        else:\n",
    "            # Check if any actual entity is not matched by prediction (by extracted_text or span)\n",
    "            for act_ent in actual_entities:\n",
    "                match_found = any(\n",
    "                    (act_ent.get(\"extracted_text\") == pred_ent.get(\"extracted_text\"))\n",
    "                    or (\n",
    "                        act_ent.get(\"start\") == pred_ent.get(\"start\")\n",
    "                        and act_ent.get(\"end\") == pred_ent.get(\"end\")\n",
    "                    )\n",
    "                    for pred_ent in predicted_entities\n",
    "                )\n",
    "                if not match_found:\n",
    "                    missed_indices.append(idx)\n",
    "                    break\n",
    "\n",
    "    return test_data_df.iloc[missed_indices]\n",
    "\n",
    "# Usage: get all rows where 'bank-routing-number' was missed\n",
    "missed_rows = get_rows_with_missed_entity(\n",
    "    test_data_df, classification_results, entity_label=\"uk-nino\",\n",
    ")\n",
    "\n",
    "len(missed_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "1f51e8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missed :\n",
      "(212) 555-0199\n"
     ]
    }
   ],
   "source": [
    "# Print all bank account numbers from the missed rows\n",
    "def extract_bank_account_numbers(df, missed_label) -> list[str]:\n",
    "    \"\"\"Extracts all unique bank account numbers from the 'mapped_output' column of the given DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing a 'mapped_output' column with entity extraction results.\n",
    "\n",
    "    Returns:\n",
    "        list[str]: List of unique bank account numbers found in the missed rows.\n",
    "    \"\"\"\n",
    "    bank_account_numbers = set()\n",
    "    for entities in df[\"mapped_output\"]:\n",
    "        # Ensure entities is a list of dicts\n",
    "        \n",
    "        if isinstance(entities, str):\n",
    "            try:\n",
    "                import ast\n",
    "                entities = ast.literal_eval(entities)\n",
    "            except (ValueError, SyntaxError):\n",
    "                entities = []\n",
    "        for ent in entities:\n",
    "            if (\n",
    "                isinstance(ent, dict)\n",
    "                and ent.get(\"label\") == missed_label\n",
    "                and ent.get(\"extracted_text\")\n",
    "            ):\n",
    "                bank_account_numbers.add(ent[\"extracted_text\"])\n",
    "    return list(bank_account_numbers)\n",
    "\n",
    "missed_bank_account_numbers = extract_bank_account_numbers(missed_rows, \"phone-number\")\n",
    "print(\"Missed :\")\n",
    "for acc_num in missed_bank_account_numbers:\n",
    "    print(acc_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3bcac3c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index=2\n",
    "text = extra_entity.iloc[index][\"text\"]\n",
    "op = call_classification_api(text)\n",
    "new_op =convert_api_response_to_entity_list(op)\n",
    "new_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "871e4a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[{'start': 44, 'end': 53, 'label': 'bank-routing-number', 'extracted_text': '778674605'}, {'start': 57, 'end': 84, 'label': 'person-name', 'extracted_text': 'Paul-Heinz Baptist Hoffmann'}, {'start': 109, 'end': 122, 'label': 'person-name', 'extracted_text': 'William Green'}]\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_entity.iloc[index][\"mapped_output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d603e1bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'start': 41,\n",
       "  'end': 53,\n",
       "  'label': 'uk-sort-code',\n",
       "  'extracted_text': '44=778674605'}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_entity.iloc[index][f\"classification_results_{experiment_name}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8af7961b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'35=D|55=ISIN US1234567890|54=1|34=123456|44=778674605|50=Paul-Heinz Baptist Hoffmann|49=Jacksontown|47=77652 William Green, 37780|10=222|\\n\\n(Explanation of the FIX Protocol fields used:\\n\\n35=D - This is the beginning of a new message.\\n55 - The security identifier (ISIN) for the trade.\\n54 - The version of the FIX Protocol being used.\\n34 - The sequence number of the message.\\n44 - The bank routing number for the trade.\\n50 - The name of the trader.\\n49 - The street address of the trader.\\n47 - The extended address of the trader.\\n10 - The checksum for the message.\\n)'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "357f928e",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_entity.to_excel(\"extra_entity.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b554b638",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"   APPLICATION FOR HOUSING BENEFIT - Section C: Personal Details. Please complete all mandatory fields marked with an asterisk (*). Full name*: Marcus Johnson. Date of birth*: 15/03/1987. National Insurance number*: TK571394B. NHS number (if known): 785 341 9672. Current residential address*: 67 Elm Grove, Leeds, LS2 9JT. Are you the tenant? YES. Contact telephone number*: +44 113 542 8671. Email address: m.johnson@email.co.uk. Bank details for payments: Sort code: 40-52-71, Account number: 63847295, Account holder: Marcus Johnson. Declaration: I certify that the information provided is true and complete. Any false statements may result in prosecution. For office use only - Reference: HB/2025/3847. Processing officer: Sarah Mitchell, Leeds City Council.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fc541799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': '', 'entityDetails': {}}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_classification_api(text, mode=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "4d31297a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9YZB123'"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[1324:1331]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1337c45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def update_license_plate_number_in_excel(\n",
    "    excel_path: str,\n",
    "    input_file_path: str,\n",
    "    experiment_col: str = \"classification_results_Experiment_5\",\n",
    "    mapped_col: str = \"mapped_output\",\n",
    "    index_col: str = \"index\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Updates the mapped_output column in the Excel file for the given index,\n",
    "    setting the mapped_output to only the license_plate_number entity/entities\n",
    "    found in the classification_results_Experiment_5 column.\n",
    "\n",
    "    Args:\n",
    "        excel_path (str): Path to the extra_entity Excel file.\n",
    "        input_file_path (str): Path to the input file (not used for writing, just for context).\n",
    "        experiment_col (str): Name of the column with classification results.\n",
    "        mapped_col (str): Name of the column to update.\n",
    "        index_col (str): Name of the index column.\n",
    "    \"\"\"\n",
    "    # Read the Excel file\n",
    "    df = pd.read_excel(excel_path)\n",
    "\n",
    "    # Ensure the experiment column exists\n",
    "    if experiment_col not in df.columns:\n",
    "        raise ValueError(f\"Column '{experiment_col}' not found in Excel file.\")\n",
    "\n",
    "    # Ensure the mapped column exists\n",
    "    if mapped_col not in df.columns:\n",
    "        raise ValueError(f\"Column '{mapped_col}' not found in Excel file.\")\n",
    "\n",
    "    # Ensure the index column exists\n",
    "    if index_col not in df.columns:\n",
    "        raise ValueError(f\"Column '{index_col}' not found in Excel file.\")\n",
    "\n",
    "    # Iterate over each row and update mapped_output for license_plate_number\n",
    "    for idx, row in df.iterrows():\n",
    "        classification_results = row[experiment_col]\n",
    "        # Defensive: handle stringified lists/dicts\n",
    "        if isinstance(classification_results, str):\n",
    "            try:\n",
    "                import ast\n",
    "                classification_results = ast.literal_eval(classification_results)\n",
    "            except Exception:\n",
    "                continue  # skip if cannot parse\n",
    "\n",
    "        if not isinstance(classification_results, list):\n",
    "            continue\n",
    "\n",
    "        # Extract only license_plate_number entities\n",
    "        license_plate_entities = [\n",
    "            entity for entity in classification_results\n",
    "            if isinstance(entity, dict) and entity.get(\"label\", \"\").lower() == \"license_plate_number\"\n",
    "        ]\n",
    "\n",
    "        # Update the mapped_output column for this row\n",
    "        df.at[idx, mapped_col] = str(license_plate_entities)\n",
    "\n",
    "    # Save the updated DataFrame back to Excel\n",
    "    df.to_excel(excel_path, index=False)\n",
    "\n",
    "# Example usage:\n",
    "# update_license_plate_number_in_excel(\"extra_entity.xlsx\", \"input_file.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84890e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "f = open(\"/Users/nishanjain/Downloads/german.txt\")\n",
    "txt = f.read()\n",
    "op = json.loads(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d4a25cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"/Users/nishanjain/Downloads/german_2.txt\")\n",
    "txt = f.read()\n",
    "op =  op + json.loads(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73a0d7b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'mapped_output', 'response_time_Experiment_5',\n",
       "       'classification_results_Experiment_5', 'response_time_Experiment_13',\n",
       "       'classification_results_Experiment_13'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91e84e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_list = []\n",
    "op_list = []\n",
    "for o in op:\n",
    "    txt_list.append(o[\"Text\"])\n",
    "    op_list.append(o[\"Entities\"])\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\"text\": txt_list, \"mapped_output\": op_list})\n",
    "df.to_excel(\"german.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7f00fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate df and test_data_df, keeping only 'text' and 'mapped_output' columns\n",
    "combined_df = pd.concat([\n",
    "    df[[\"text\", \"mapped_output\"]],\n",
    "    test_data_df[[\"text\", \"mapped_output\"]]\n",
    "], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "40df6451",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_df = combined_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc36fbd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1675"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "01fe54d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "7d9bd009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0 of 41\n"
     ]
    }
   ],
   "source": [
    "classification_results, response_time = aggregate_classification_results(df, text_column=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "e54103bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "df[f\"response_time_{experiment_name}\"] = response_time\n",
    "df[f\"classification_results_{experiment_name}\"] = classification_results\n",
    "#test_data_df.to_excel(input_excel, index=False)\n",
    "experiment_time = time.time() - start_time\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "7d499caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_type</th>\n",
       "      <th>actual_count</th>\n",
       "      <th>correct</th>\n",
       "      <th>extra</th>\n",
       "      <th>missed</th>\n",
       "      <th>wrong</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>email-address</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>german-drivers-license-number</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>german-identity-card-number</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>german-passport-number</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>german-vat-number</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>phone-number</td>\n",
       "      <td>61</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>0.983607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>date-of-birth</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.936170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>german-tax-identification-number</td>\n",
       "      <td>34</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.903226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>organization</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>person-name</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>street-address</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         entity_type  actual_count  correct  extra  missed  \\\n",
       "0                      email-address            11       11      0       0   \n",
       "1      german-drivers-license-number            24       24      0       0   \n",
       "2        german-identity-card-number            44       44      0       0   \n",
       "3             german-passport-number            12       12      0       0   \n",
       "4                  german-vat-number            25       25      0       0   \n",
       "5                       phone-number            61       60      1       1   \n",
       "6                      date-of-birth            22       22      3       0   \n",
       "7   german-tax-identification-number            34       28      0       6   \n",
       "8                       organization           143        0      0     143   \n",
       "9                        person-name           106        0      0     106   \n",
       "10                    street-address            81        0      0      81   \n",
       "\n",
       "    wrong  accuracy  precision    recall        f1  \n",
       "0       0  1.000000   1.000000  1.000000  1.000000  \n",
       "1       0  1.000000   1.000000  1.000000  1.000000  \n",
       "2       0  1.000000   1.000000  1.000000  1.000000  \n",
       "3       0  1.000000   1.000000  1.000000  1.000000  \n",
       "4       0  1.000000   1.000000  1.000000  1.000000  \n",
       "5       0  0.967742   0.983607  0.983607  0.983607  \n",
       "6       0  0.880000   0.880000  1.000000  0.936170  \n",
       "7       0  0.823529   1.000000  0.823529  0.903226  \n",
       "8       0  0.000000   0.000000  0.000000  0.000000  \n",
       "9       0  0.000000   0.000000  0.000000  0.000000  \n",
       "10      0  0.000000   0.000000  0.000000  0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro-averaged metrics across all entities:\n",
      "macro_accuracy: 0.697\n",
      "macro_precision: 0.715\n",
      "macro_recall: 0.710\n",
      "macro_f1: 0.711\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "# Assume test_data_df[\"mapped_output\"] and classification_results are both lists of dicts per row\n",
    "entity_metrics_df, macro_metrics = compute_entity_metrics_for_lists(\n",
    "    df, actual_col=test_column, pred_col=f\"classification_results_{experiment_name}\"\n",
    ")\n",
    "# Sort the entity_metrics_df by f1 score in descending order for better interpretability\n",
    "entity_metrics_df = entity_metrics_df.sort_values(by=\"f1\", ascending=False).reset_index(drop=True)\n",
    "#entity_metrics_df = entity_metrics_df[entity_metrics_df[\"f1\"] > 0].reset_index(drop=True)\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "display(entity_metrics_df[[\"entity_type\", \"actual_count\", \"correct\", \"extra\", \"missed\", \"wrong\", \"accuracy\", \"precision\", \"recall\", \"f1\"]])\n",
    "print(\"Macro-averaged metrics across all entities:\")\n",
    "for k, v in macro_metrics.items():\n",
    "    print(f\"{k}: {v:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "20ad13c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_entity = get_rows_with_extra_entity(df, \"german-tax-identification-number\", \"mapped_output\", f\"classification_results_{experiment_name}\")\n",
    "len(extra_entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df1a497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "BASE_URL = \"http://localhost:8000\"\n",
    "def call_classification_api(text, mode=\"all\", anonymize=False):\n",
    "    \"\"\"\n",
    "    Call the Pebblo classification API\n",
    "    \n",
    "    Args:\n",
    "        text (str): The text to classify\n",
    "        mode (str): Classification mode - \"all\", \"entity\", or \"topic\"\n",
    "        anonymize (bool): Whether to anonymize the results\n",
    "    \n",
    "    Returns:\n",
    "        dict: The classification response\n",
    "    \"\"\"\n",
    "    url = f\"{BASE_URL.rstrip('/')}/api/v1/classify\"\n",
    "    \n",
    "    # Prepare the request payload without llm_config\n",
    "    payload = {\n",
    "        \"text\": text,\n",
    "        \"anonymize\": anonymize,\n",
    "        \"country_list\": [\"US\"]\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        #print(\"payload\", payload)\n",
    "        response = requests.post(url, json=payload)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error making API request: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6be9379c",
   "metadata": {},
   "outputs": [],
   "source": [
    "missed_rows = get_rows_with_missed_entity(df, \n",
    "                                        classification_results, \n",
    "                                        entity_label=\"german-identity-card-number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5fa8a015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': \"REGISTRATION FORM - Berlin District Office, Registration Authority. PERSONAL INFORMATION: Name: Dr. Klaus Mueller, Date of Birth: 15.07.1985, Identity Card Number: T48000129, Passport Number: C22T3MX16. Previous Address: Kantstraße 45, 10625 Berlin. New Address: Alexanderplatz 12, 10178 Berlin. Phone: +49 30 2847 3952, Email: k.mueller@email.de. TAX INFORMATION: Tax Identification Number: 32 594 78 302 8, VAT Number: DE287435898 (for freelance legal services). BANK DETAILS: Deutsche Bank AG, IBAN: DE89 3704 0044 0532 0130 00. EMPLOYER: Law Firm Schmidt & Partners, Unter den Linden 25, 10117 Berlin, Tel: +49 30 2094 5678. Driver's License Number: B35K7M9N24C, issued 22.03.2018. Marital Status: married to Anna Mueller, née Weber. Applicant signature required. Processing fee: 15.00 Euro. Responsible clerk: Mr. Thomas Schmidt, Room 205.\",\n",
       " 'entityCount': 10,\n",
       " 'entities': {'date-of-birth': 1,\n",
       "  'german-identity-card-number': 1,\n",
       "  'german-passport-number': 1,\n",
       "  'phone-number': 2,\n",
       "  'email-address': 1,\n",
       "  'german-tax-identification-number': 1,\n",
       "  'german-vat-number': 1,\n",
       "  'iban-code': 1,\n",
       "  'german-drivers-license-number': 1},\n",
       " 'entityDetails': {'date-of-birth': [{'location': '130_140',\n",
       "    'confidence_score': 0.8,\n",
       "    'entity_group': 'pii-identification'}],\n",
       "  'german-identity-card-number': [{'location': '164_173',\n",
       "    'confidence_score': 0.8,\n",
       "    'entity_group': 'de-pii-identification'}],\n",
       "  'german-passport-number': [{'location': '192_201',\n",
       "    'confidence_score': 0.8,\n",
       "    'entity_group': 'de-pii-identification'}],\n",
       "  'phone-number': [{'location': '303_319',\n",
       "    'confidence_score': 0.8,\n",
       "    'entity_group': 'pii-contact'},\n",
       "   {'location': '611_627',\n",
       "    'confidence_score': 0.8,\n",
       "    'entity_group': 'pii-contact'}],\n",
       "  'email-address': [{'location': '328_346',\n",
       "    'confidence_score': 1.0,\n",
       "    'entity_group': 'pii-contact'}],\n",
       "  'german-tax-identification-number': [{'location': '392_407',\n",
       "    'confidence_score': 0.8,\n",
       "    'entity_group': 'de-pii-financial'}],\n",
       "  'german-vat-number': [{'location': '421_432',\n",
       "    'confidence_score': 0.8,\n",
       "    'entity_group': 'de-pii-financial'}],\n",
       "  'iban-code': [{'location': '503_530',\n",
       "    'confidence_score': 1.0,\n",
       "    'entity_group': 'pii-financial'}],\n",
       "  'german-drivers-license-number': [{'location': '654_665',\n",
       "    'confidence_score': 0.8,\n",
       "    'entity_group': 'de-pii-identification'}]},\n",
       " 'topicCount': 2,\n",
       " 'topics': {'LEGAL': 1, 'FINANCE': 1},\n",
       " 'topicDetails': {'LEGAL': [{'confidence_score': 'MEDIUM'}],\n",
       "  'FINANCE': [{'confidence_score': 'MEDIUM'}]},\n",
       " 'compliance': {'HIPAA': False, 'GDPR': False}}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a951ba73",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "RMEDICAL CERTIFICATE - Dr. med. Petra Hoffmann, Specialist in Internal Medicine. Practice: North Health Center, Hamburger Straße 89, 20459 Hamburg, Tel: +49 40 3847 2956. PATIENT DETAILS: Mrs. Maria Schneider, born 23.04.1978, residing at: Rosenstraße 34, 22301 Hamburg, Tel: +49 40 8394 5627. Identity Card: L32RX8H29D, Health Insurance: AOK Hamburg, Insurance Number: M847392654. DIAGNOSIS: Acute bronchitis (ICD-10: J20.9), first occurred on 18.10.2025. TREATMENT: Antibiotic therapy with Amoxicillin 500mg, three times daily for 7 days. Medical leave from 19.10.2025 to 26.10.2025 (8 calendar days). FOLLOW-UP: Control examination scheduled for 28.10.2025 at 2:30 PM. Return immediately if symptoms worsen. Doctor's tax details: Tax ID: 41 738 29 465 6, VAT ID: DE394728565. Patient's driver's license: H72M3N8V39C (temporary driving restriction due to medication). Hamburg, October 19, 2025. Dr. med. Petra Hoffmann, Physician.\"\n",
    " **Medical Loan Application**\n",
    "\n",
    "Full Name: Reiner P. Misicher\n",
    "Date of Birth: DD/MM/YYYY\n",
    "National Insurance Number: MLNSPH31D16F536O\n",
    "Contact Telephone Number: [+44] 1234567890\n",
    "Email Address: r.misicher@example.com\n",
    "\n",
    "Residential Address: 89, rue Auguste Lelièvre, London, N1 9AB, United Kingdom\n",
    "\n",
    "Employment Information:\n",
    "Employer's Name: St. Bartholomew's Hospital\n",
    "Job Title: Consultant Cardiologist\n",
    "Annual Income: £90,000\n",
    "\n",
    "Medical History:\n",
    "1. Chronic Condition: Hypertension - Diagnosed in 2010\n",
    "2. Current Medications: Ramipril 5mg, Amlodipine 10mg\n",
    "3. Allergies: No known allergies\n",
    "\n",
    "Loan Information:\n",
    "Loan Amount Requested: £20,000\n",
    "Loan Purpose: Heart Valve Replacement Surgery\n",
    "Estimated Treatment Cost: £25,000\n",
    "Hospital: King's College Hospital, London\n",
    "Tentative Surgery Date: 01/10/2023\n",
    "Referring Physician: Dr. Sarah K. Johnson, Consultant Cardiothoracic Surgeon\n",
    "\n",
    "Personal Declaration:\n",
    "I, Reiner P. Misicher, hereby declare that all the information provided in this loan application is true and accurate to the best of my knowledge. I understand that any misrepresentation of facts may lead to the cancellation of the loan or legal consequences.\n",
    "\n",
    "Signature: Reiner P. Misicher\n",
    "Date: DD/MM/YYYY\n",
    "Email Address: r.misicher@example.com\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "341d11c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': '',\n",
       " 'entityDetails': {'us-drivers-license': [{'location': '371_381',\n",
       "    'confidence_score': 0.3,\n",
       "    'entity_value': 'M847392654',\n",
       "    'start_index': 371,\n",
       "    'end_index': 381}],\n",
       "  'phone-number': [{'location': '1092_1108',\n",
       "    'confidence_score': 0.75,\n",
       "    'entity_value': '[+44] 1234567890',\n",
       "    'start_index': 1092,\n",
       "    'end_index': 1108}],\n",
       "  'email-address': [{'location': '1124_1146',\n",
       "    'confidence_score': 1.0,\n",
       "    'entity_value': 'r.misicher@example.com',\n",
       "    'start_index': 1124,\n",
       "    'end_index': 1146},\n",
       "   {'location': '2143_2165',\n",
       "    'confidence_score': 1.0,\n",
       "    'entity_value': 'r.misicher@example.com',\n",
       "    'start_index': 2143,\n",
       "    'end_index': 2165}]}}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 0\n",
    "#text = missed_rows.iloc[index][\"text\"]\n",
    "op = call_classification_api_2(text)\n",
    "op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dc8c6e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def call_classification_api_2(text, mode=\"all\", anonymize=False):\n",
    "    \"\"\"\n",
    "    Call the Pebblo classification API\n",
    "    \n",
    "    Args:\n",
    "        text (str): The text to classify\n",
    "        mode (str): Classification mode - \"all\", \"entity\", or \"topic\"\n",
    "        anonymize (bool): Whether to anonymize the results\n",
    "    \n",
    "    Returns:\n",
    "        dict: The classification response\n",
    "    \"\"\"\n",
    "    url = f\"{BASE_URL.rstrip('/')}/api/v1/classify\"\n",
    "    \n",
    "    # Prepare the request payload without llm_config\n",
    "    payload = {\n",
    "        \"text\": text,\n",
    "        \"anonymize\": anonymize,\n",
    "        \"country_list\": [\"US\"]\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        #print(\"payload\", payload)\n",
    "        response = requests.post(url, json=payload)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error making API request: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45b24cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
